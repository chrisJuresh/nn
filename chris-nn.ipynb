{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c880eee1-5e5b-489d-aa36-f513d105cc99",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dbe134-8d85-4ce2-8731-3351027fbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c6051-8288-4ce8-a2a5-c29d7e82c4e7",
   "metadata": {},
   "source": [
    "# Cutout transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42173cfa-fdb4-4a31-9374-0cfbb6017257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom cutout augmentation\n",
    "class Cutout(object):\n",
    "    \"\"\"\n",
    "    Randomly masks out one or more patches from an image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1:y2, x1:x2] = 0.0\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img *= mask\n",
    "\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ce0cd-5d95-4d63-8fbd-a5db10b509cd",
   "metadata": {},
   "source": [
    "# 1. Read dataset and create dataloaders: 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f49c3c10-7b62-4c77-bc7b-0ad0a32b24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dataset augmentation transformation\n",
    "transform_augmented = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        Cutout(n_holes=1, length=16),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation and testing dataset transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "# Training data\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_augmented\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "# Testing data\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1532a25-5ccc-4355-8ad8-2b3f920757c6",
   "metadata": {},
   "source": [
    "# 2. Create the model: 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d575dcde-1812-4edf-a9a1-ed34abc5f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A block within the Backbone.\n",
    "\n",
    "    Consists of:\n",
    "        Linear layer.\n",
    "        SpatialAveragePool.\n",
    "        K Conv layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_convs, kernel_size=3):\n",
    "        super(Block, self).__init__()\n",
    "        # SpatialAveragePool to vector of d channels\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        # Linear layer transforming pooled output to a vector with K elements\n",
    "        self.fc = nn.Linear(in_channels, num_convs)\n",
    "        # K Conv layers\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels, out_channels, kernel_size, padding=kernel_size // 2\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(out_channels),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "                for _ in range(num_convs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Calculating weight vector a = [a1, ..., ak] with g\n",
    "        weight_vector = F.softmax(self.fc(self.avg_pool(x).squeeze()), dim=-1)\n",
    "        conv_outputs = torch.stack([conv(x) for conv in self.convs], dim=2)\n",
    "        # Combining Conv layer outputs with calculated weights a to produce a single output O.\n",
    "        weighted_output = torch.sum(\n",
    "            conv_outputs * weight_vector.unsqueeze(1).unsqueeze(-1).unsqueeze(-1), dim=2\n",
    "        )\n",
    "        return weighted_output\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    \"\"\"\n",
    "    Consists of N Blocks, each with a certain number of convolutional layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_blocks, num_convs, in_channels=3, out_channels_sequence=[32, 64, 128]\n",
    "    ):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.features = nn.Sequential()\n",
    "\n",
    "        # Constructing Blocks and Pooling layers\n",
    "        for i, num_block in enumerate(num_blocks):\n",
    "            for j in range(num_block):\n",
    "                self.features.add_module(\n",
    "                    f\"block_{i}_{j}\",\n",
    "                    Block(in_channels, out_channels_sequence[i], num_convs),\n",
    "                )\n",
    "                in_channels = out_channels_sequence[i]\n",
    "            self.features.add_module(f\"pool_{i}\", nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the mean feature vector ƒ by applying SpatialAveragePool to the Backbone's output. Then passes ƒ through a MLP classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        # Computes a mean feature vector ƒ by applying SpatialAveragePool to the Backbone's output.\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        hidden_features = in_features * 2\n",
    "\n",
    "        # MLP classifier\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture based on Convolutional Neural Networks that uses a Backbone and a Classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, num_blocks=[2, 2, 2], num_convs=3):\n",
    "        super(Model, self).__init__()\n",
    "        out_channels_sequence = [32, 64, 128]\n",
    "\n",
    "        # Backbone\n",
    "        self.backbone = Backbone(\n",
    "            num_blocks,\n",
    "            num_convs,\n",
    "            in_channels=3,\n",
    "            out_channels_sequence=out_channels_sequence,\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        final_in_channels = out_channels_sequence[-1]\n",
    "        self.classifier = Classifier(final_in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        # Process the output of the last Block in the Backbone through Classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Initialize model\n",
    "num_classes = 20\n",
    "net = Model(num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af04dbb-4a54-470d-93ed-188cfab2f994",
   "metadata": {},
   "source": [
    "# 3. Create the loss and optimizer: 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b572be03-a753-4780-8a05-f341b375d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2621ce-3434-4992-bdc1-c16d9ea3e80c",
   "metadata": {},
   "source": [
    "# 4. Write the training script to train the model. 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a831c65-4a12-4fa6-8e1c-03f43c1d9d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.5914, Train Accuracy: 0.4103, Test Loss: 1.8924, Test Accuracy: 0.4169\n",
      "Epoch [2/50], Train Loss: 1.2247, Train Accuracy: 0.5581, Test Loss: 1.7814, Test Accuracy: 0.5139\n",
      "Epoch [3/50], Train Loss: 1.0722, Train Accuracy: 0.6180, Test Loss: 0.9778, Test Accuracy: 0.6641\n",
      "Epoch [4/50], Train Loss: 0.9753, Train Accuracy: 0.6544, Test Loss: 1.2403, Test Accuracy: 0.6028\n",
      "Epoch [5/50], Train Loss: 0.8900, Train Accuracy: 0.6891, Test Loss: 0.7572, Test Accuracy: 0.7398\n",
      "Epoch [6/50], Train Loss: 0.8370, Train Accuracy: 0.7102, Test Loss: 0.7632, Test Accuracy: 0.7308\n",
      "Epoch [7/50], Train Loss: 0.7855, Train Accuracy: 0.7293, Test Loss: 0.8218, Test Accuracy: 0.7490\n",
      "Epoch [8/50], Train Loss: 0.7530, Train Accuracy: 0.7408, Test Loss: 0.6344, Test Accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy helper\n",
    "def calculate_accuracy(y_pred, y_true):\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct = (predicted == y_true).float().sum()\n",
    "    accuracy = correct / y_true.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Calculate training loss and accuracy\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, running_accuracy = 0.0, 0.0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += calculate_accuracy(outputs, labels).item()\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    avg_accuracy = running_accuracy / len(loader)\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss, test_accuracy = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_accuracy += calculate_accuracy(outputs, labels).item()\n",
    "\n",
    "    avg_loss = test_loss / len(loader)\n",
    "    avg_accuracy = test_accuracy / len(loader)\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "# Initialise lists to store metrics\n",
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "\n",
    "# Initialise training variables\n",
    "num_epochs = 50\n",
    "\n",
    "# Training and testing loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train_epoch(\n",
    "        net, trainloader, optimizer, criterion, device\n",
    "    )\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    test_loss, test_accuracy = evaluate_model(net, testloader, criterion, device)\n",
    "\n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Print live metrics\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "        f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9c8e1-5442-4937-b34a-ebe1fa688770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plotting both loss and accuracy on the same axis\n",
    "ax.plot(train_losses, label='Train Loss', color='tab:blue', linestyle='dashed')\n",
    "ax.plot(test_losses, label='Test Loss', color='tab:orange', linestyle='dashed')\n",
    "ax.plot(train_accuracies, label='Train Accuracy', color='tab:blue')\n",
    "ax.plot(test_accuracies, label='Test Accuracy', color='tab:orange')\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy / Validation')\n",
    "plt.title('Training and Testing Metrics per Epoch')\n",
    "\n",
    "# Adding a legend to distinguish between the plots\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71401b-978e-4f05-aae2-cd2e618c1d45",
   "metadata": {},
   "source": [
    "# 5. Final model accuracy on CIFAR-10 Validation Set: 20%\n",
    "I achieved 90% or 91% consistently with this model locally (3080ti) and on Google Collab (T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58e435-5388-43dc-aa64-445d51a8e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TAKEN FROM https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Final model accuracy: {100 * correct / total:.4f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
